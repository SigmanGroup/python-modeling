{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T03:53:31.940766Z",
     "start_time": "2019-07-07T03:53:31.935868Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/annabell/UofU/Sigman/python-modeling'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32manna\u001b[m\n",
      "  master\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T21:29:45.261446Z",
     "start_time": "2021-11-17T21:29:45.239505Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, sys, pickle, datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest,f_regression,mutual_info_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression,Ridge,ElasticNetCV,ElasticNet,Lars,LassoCV,RidgeCV,LarsCV,LassoLarsCV,LassoLarsIC,OrthogonalMatchingPursuitCV,OrthogonalMatchingPursuit\n",
    "from sklearn.manifold import TSNE,MDS\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RepeatedKFold,LeaveOneOut,cross_val_score,cross_validate\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "#from sklearn import tree\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import multiprocessing\n",
    "nproc = max([1,multiprocessing.cpu_count()-2])\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import loo_q2 as loo\n",
    "\n",
    "randomstate = 42\n",
    "\n",
    "def plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"y\",loo_pred=[]):\n",
    "    y_orig_min = np.min(np.hstack((y_train,y_test)))\n",
    "    y_pred_min = np.min(np.hstack((y_pred_train,y_pred_test)))\n",
    "    y_orig_max = np.max(np.hstack((y_train,y_test)))\n",
    "    y_pred_max = np.max(np.hstack((y_pred_train,y_pred_test)))\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)\n",
    "           \n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    # plt.plot(np.linspace(y_orig_min-delta_x,y_orig_max+delta_x), np.linspace(y_orig_min-delta_x,y_orig_max+delta_x),color=\"grey\")\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\".\",facecolor='none',s=200)\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"black\",marker=\".\",s=200) # ,alpha=0.6\n",
    "    plt.scatter(y_test,y_pred_test,label=\"test\",color='red',marker=\".\",linewidth=3, s=200)     #,alpha=0.25  \"#8da9f5\"\n",
    "    plt.plot(y_train,yy_fit_line,color=\"darkgrey\",linestyle='--',dashes=[5,15]) #,alpha=0.2\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.xlabel(label+\" measured\",fontsize=18, fontweight='bold')\n",
    "    plt.ylabel(label+\" predicted\",fontsize=18, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    \n",
    "    plt.gca().spines['right'].set_color('none')\n",
    "    plt.gca().spines['top'].set_color('none')\n",
    "    \n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav, dpi=300, bbox_inches='tight', transparent=True)\n",
    "        \n",
    "def r2_val(y_test,y_pred_test,y_train):\n",
    "    \"\"\"Calculates the external R2 pred as described:\n",
    "    https://pdfs.semanticscholar.org/4eb2/5ff5a87f2fd6789c5b9954eddddfd1c59dab.pdf\"\"\"\n",
    "    y_resid = y_pred_test - y_test\n",
    "    SS_resid = np.sum(y_resid**2)\n",
    "    y_var = y_test - np.mean(y_train)\n",
    "    SS_total = np.sum(y_var**2)\n",
    "    r2_validation = 1-SS_resid/SS_total\n",
    "    return(r2_validation)\n",
    "\n",
    "def repeated_k_fold(X_train,y_train,reg = LinearRegression(), k=3, n=100):\n",
    "    \"\"\"Reapeated k-fold cross-validation. \n",
    "    For each of n repeats, the (training)data is split into k folds. \n",
    "    For each fold, this part of the data is predicted using the rest. \n",
    "    Once this is done for all k folds, the coefficient of determination (R^2) of the predictions of all folds combined (= the complete data set) is evaluated\n",
    "    This is repeated n times and all n R^2 are returned for averaging/further analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n)\n",
    "    r2_scores = []\n",
    "    y_validations,y_predictions = np.zeros((np.shape(X_train)[0],n)),np.zeros((np.shape(X_train)[0],n))\n",
    "    foldcount = 0\n",
    "    for i,foldsplit in enumerate(rkf.split(X_train)):\n",
    "        fold, rep = i%k, int(i/k) # Which of k folds. Which of n repeats\n",
    "        model = reg.fit(X_train[foldsplit[0]],y_train[foldsplit[0]]) # foldsplit[0]: k-1 training folds\n",
    "        y_validations[foldcount:foldcount+len(foldsplit[1]),rep] = y_train[foldsplit[1]] # foldsplit[1]: validation fold\n",
    "        y_predictions[foldcount:foldcount+len(foldsplit[1]),rep]  = model.predict(X_train[foldsplit[1]])\n",
    "        foldcount += len(foldsplit[1])\n",
    "        if fold+1==k:\n",
    "            foldcount = 0\n",
    "    r2_scores = np.asarray([metrics.r2_score(y_validations[:,rep],y_predictions[:,rep]) for rep in range(n)])\n",
    "    return(r2_scores)\n",
    "\n",
    "# keepmodels = []\n",
    "\n",
    "import random\n",
    "insu = [\"yikes. that's ass.\",\"LMAO do not publish this what are you doing\",\"oof.\",\"that's a rough one\",\"I'm embarassed to even print this, but here it is:\",\"more disappointing than an unsalted pretzel\",\"this model makes onions cry\",\"did you get this model from Joe?\",\"remember, these stats aren't an insult, they're just describing your model\",\"this model reminds me - I gotta take out the trash\",\"don't worry - the first 40 years of modeling are always the hardest\",\"this model has miles to go before it reaches mediocre\",\"the bad model store called. they're running out of your models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T20:27:56.667284Z",
     "start_time": "2021-11-15T20:27:48.656818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env export > environment_2.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:01:39.171956Z",
     "start_time": "2021-11-22T22:01:38.913648Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples before removing empty cells: 24\n",
      "Removing 0 samples.\n",
      "Shape X: (24, 2)\n",
      "Shape y: (24,)\n",
      "Shape labels: (24,)\n",
      "First X cell: -0.59232\n",
      "Last X cell:  -0.88981\n",
      "First y: 6.0\n",
      "Last y:  0.0\n",
      "Last label: L15\n"
     ]
    }
   ],
   "source": [
    "# all data in a single file\n",
    "excel_file =\"model_oct_bothsubs\" \n",
    "excel_sheet = \"bubbleplot\" #\"singlesub\" #\"no_NH_no_diffaryl\" \n",
    "num_par = 2 #190 \n",
    "par_start_col = 9 #4  # 0-indexed\n",
    "num_samples = 24 #68 #24 #34 \n",
    "response_col = 5 #2   # 0-indexed\n",
    "y_label_col = 0    # 0-indexed\n",
    "\n",
    "apply_mask = True # remove samples with empty response\n",
    "verbose = True\n",
    "xlabelrow = True\n",
    "\n",
    "\n",
    "inp = pd.read_excel(excel_file+\".xlsx\",excel_sheet,header=4,index_col=y_label_col,nrows=num_samples+int(xlabelrow),\n",
    "                    usecols=list(range(0,(num_par+par_start_col))))\n",
    "\n",
    "if xlabelrow:\n",
    "    X_names = list(inp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "    inp.drop(index=inp.index[0],inplace=True)\n",
    "else:\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    X_names = X_labels\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "y = np.asarray(inp[resp_label],dtype=np.float)\n",
    "X = np.asarray(inp[X_labels],dtype=np.float)\n",
    "y_labels = np.asarray(list(inp.index),dtype=str)\n",
    "y_labels_comp= y_labels\n",
    "\n",
    "if apply_mask:\n",
    "    mask = y.nonzero()[0]\n",
    "    mask = ~np.isnan(y)\n",
    "    print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "    print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "    X = X[np.array(mask)]\n",
    "    y = y[np.array(mask)]\n",
    "    y_labels = y_labels[np.array(mask)]\n",
    "X_all = X\n",
    "if verbose:\n",
    "    print(\"Shape X: {}\".format(X.shape))\n",
    "    print(\"Shape y: {}\".format(y.shape)) \n",
    "    print(\"Shape labels: {}\".format(y_labels.shape)) \n",
    "    print(\"First X cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label: {}\".format(y_labels[-1]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>s2_1h_%yield</th>\n",
       "      <th>s2_3.5h_%yield(avg)</th>\n",
       "      <th>s2_21h_%yield</th>\n",
       "      <th>s4_1h_%yield</th>\n",
       "      <th>s4_3.5h_%yield(avg)</th>\n",
       "      <th>s4_21h_%yield</th>\n",
       "      <th>virtual</th>\n",
       "      <th>x49</th>\n",
       "      <th>x73</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L21</th>\n",
       "      <td>CN(c1cccc[nH+]1)S(=O)(=O)c2cccc(c2NC(=O)C(=O)O...</td>\n",
       "      <td>23</td>\n",
       "      <td>78.666667</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5904</td>\n",
       "      <td>-0.88058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L22</th>\n",
       "      <td>CC(C)NS(=O)(=O)c1cccc(c1NC(=O)C(=O)O)F</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.56822</td>\n",
       "      <td>-0.90508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L24</th>\n",
       "      <td>c1c(cc(c(c1F)NC(=O)C(=O)O)S(=O)(=O)N2CCCCC2)F</td>\n",
       "      <td>24</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.59197</td>\n",
       "      <td>-0.89574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L25</th>\n",
       "      <td>c1ccc(c(c1)NC(=O)C(=O)O)S(=O)(=O)N2CCCCC2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.58696</td>\n",
       "      <td>-0.91436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L15</th>\n",
       "      <td>CC(C)N(c1ccccc1)S(=O)(=O)c2cccc(c2NC(=O)C(=O)O)F</td>\n",
       "      <td>18</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.59232</td>\n",
       "      <td>-0.88981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES s2_1h_%yield  \\\n",
       "ID                                                                    \n",
       "L21  CN(c1cccc[nH+]1)S(=O)(=O)c2cccc(c2NC(=O)C(=O)O...           23   \n",
       "L22             CC(C)NS(=O)(=O)c1cccc(c1NC(=O)C(=O)O)F            0   \n",
       "L24      c1c(cc(c(c1F)NC(=O)C(=O)O)S(=O)(=O)N2CCCCC2)F           24   \n",
       "L25          c1ccc(c(c1)NC(=O)C(=O)O)S(=O)(=O)N2CCCCC2            1   \n",
       "L15   CC(C)N(c1ccccc1)S(=O)(=O)c2cccc(c2NC(=O)C(=O)O)F           18   \n",
       "\n",
       "    s2_3.5h_%yield(avg) s2_21h_%yield s4_1h_%yield s4_3.5h_%yield(avg)  \\\n",
       "ID                                                                       \n",
       "L21           78.666667            82            6           41.333333   \n",
       "L22            3.666667            23            0           11.333333   \n",
       "L24           72.333333            88            7           35.666667   \n",
       "L25            3.666667            18            0            1.666667   \n",
       "L15           60.333333            86            0           32.333333   \n",
       "\n",
       "    s4_21h_%yield virtual      x49      x73  \n",
       "ID                                           \n",
       "L21            79       0  -0.5904 -0.88058  \n",
       "L22            30       0 -0.56822 -0.90508  \n",
       "L24            60       0 -0.59197 -0.89574  \n",
       "L25            13       0 -0.58696 -0.91436  \n",
       "L15            66       0 -0.59232 -0.88981  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T22:35:17.471142Z",
     "start_time": "2020-11-10T22:35:02.207032Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Phosphine_library_DFT_props_191120_copy.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bc411f731c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_label_col_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# 0-indexed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcompinp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_file\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomp_sheet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_label_col_comp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomp_num_samples\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_par\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpar_start_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mcompinp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompinp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mexpinp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_file\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_sheet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_label_col_exp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_num_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse_col\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1072\u001b[0m                     \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(path, content, storage_options)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcontent_or_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     ) as handle:\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Phosphine_library_DFT_props_191120_copy.xlsx'"
     ]
    }
   ],
   "source": [
    "## separate files for exp data and comp data\n",
    "\n",
    "comp_file = \"Phosphine_library_DFT_props_191120_copy\" \n",
    "comp_sheet = \"selprops_use_2_bowls\" \n",
    "num_par = 182 \n",
    "par_start_col = 1   # 0-indexed\n",
    "comp_num_samples = 1359 \n",
    "y_label_col_comp = 0  # 0-indexed\n",
    "\n",
    "exp_file = \"exp_bowls\" \n",
    "exp_sheet = \"Sheet1\"\n",
    "exp_num_samples = 10 \n",
    "response_col = 9  # 0-indexed\n",
    "y_label_col_exp = 0  # 0-indexed\n",
    "\n",
    "compinp = pd.read_excel(comp_file+\".xlsx\",comp_sheet,header=0,index_col=y_label_col_comp,nrows=comp_num_samples+1,usecols=list(range(0,(num_par+par_start_col))))\n",
    "compinp.index = compinp.index.map(str)\n",
    "expinp = pd.read_excel(exp_file+\".xlsx\",exp_sheet,header=4,index_col=y_label_col_exp,nrows=exp_num_samples,usecols=list(range(0,response_col+1)))\n",
    "expinp.index = [i.zfill(4) for i in expinp.index.map(str)]\n",
    "\n",
    "xlabelrow = True\n",
    "verbose = True\n",
    "\n",
    "X_names = list(compinp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "X_labels = list(compinp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "compinp.drop(index=compinp.index[0],inplace=True)\n",
    "X_all = np.asarray(compinp[X_labels],dtype=np.float)\n",
    "y_labels_comp = np.asarray(list(compinp.index),dtype=str)\n",
    "compnan = np.isnan(X_all).any(axis=1)\n",
    "y_labels_comp,X_all = y_labels_comp[~compnan],X_all[~compnan]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "\n",
    "resp_label = list(expinp.columns)[response_col-1]\n",
    "y = np.asarray(expinp.iloc[:,response_col-1],dtype=np.float)\n",
    "y_labels_exp = np.asarray(list(expinp.index),dtype=str)\n",
    "\n",
    "mask_y = y.nonzero()[0]\n",
    "mask_y = ~np.isnan(y)\n",
    "mask_X = np.array([True if i in y_labels_comp else False for i in y_labels_exp])\n",
    "mask = mask_y&mask_X\n",
    "print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "y = y[np.array(mask)]\n",
    "y_labels = y_labels_exp[np.array(mask)]\n",
    "\n",
    "X = np.asarray(compinp.loc[y_labels],dtype=np.float)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Shape X (all): {}\".format(X_all.shape))\n",
    "    print(\"Shape X (exp): {}\".format(X.shape))\n",
    "    print(\"Shape y (exp): {}\".format(y.shape)) \n",
    "    print(\"Shape labels (exp): {}\".format(y_labels.shape)) \n",
    "    print(\"First X (exp) cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X (exp) cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label exp: {}\".format(y_labels[-1]))\n",
    "    print(\"Last label comp: {}\".format(y_labels_comp[-3:]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and univariate correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T20:57:55.527600Z",
     "start_time": "2021-11-08T20:56:27.638541Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original data\n",
    "# Visualize Histograms and univariate correlations for all (or selected) features\n",
    "features = range(np.shape(X)[1])   # iterate over all features\n",
    "# examples for selecting features\n",
    "#specify names:\n",
    "# features = [x_names.index(\"sterimol_5-.5cB5_max\")]\n",
    "#specify x-numbers (1-indexed):\n",
    "#features_x = [\"x139\",\"x140\",\"x141\",\"x142\",\"x143\",\"x144\",\"x145\",\"x146\",\"x147\",\"x148\",\"x149\",\"x150\",\"x151\",\"x152\",\"x153\",\"x154\",\"x155\",\"x156\",\"x157\",\"x158\",\"x159\",\"x160\",\"x161\",\"x162\",\"x163\"]\n",
    "#features = [X_labels.index(i) for i in features_x]\n",
    "#specify ranges (0-indexed)\n",
    "#features = itertools.chain(range(15,92)) #480,2611)) #312,343)) \n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    print(feature, X_names[f_ind])\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind], y)\n",
    "    fit_line = intercept+slope*X[:,f_ind]\n",
    "    \n",
    "    plt.figure(figsize=(9, 4))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(X[:,f_ind], bins=\"auto\")\n",
    "    plt.ylabel(\"frequency\",fontsize=20)\n",
    "    plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=20)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(X[:,f_ind], y,color=\"black\",marker=\"s\",alpha=0.5)    \n",
    "    plt.plot(X[:,f_ind],fit_line,color=\"black\")\n",
    "    plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=20)\n",
    "    plt.ylabel(\"y\",fontsize=20) # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "#     plt.xticks(np.arange(round(min(X[:,f_ind])-0.005,3), round(max(X[:,f_ind])+0.005,3), 0.03),fontsize=15)\n",
    "    plt.yticks(fontsize=15)        \n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "    if p_value > 0.01:\n",
    "        print(\"R^2 = {:.2f}; p-value = {:.2f}\".format(r_value**2,p_value))\n",
    "    else:\n",
    "        print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "    print(\"\\n-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:00:33.281767Z",
     "start_time": "2021-11-08T21:00:32.125067Z"
    }
   },
   "outputs": [],
   "source": [
    "# has option to only print univariate correlations if they meet an R^2 cutoff\n",
    "\n",
    "### All features:\n",
    "features = range(np.shape(X)[1])\n",
    "### Features by X-numbers (1-indexed):\n",
    "#features_x = [\"x1\",\"x19\",\"x20\",\"x31\",\"x120\",\"x145\",\"x160\"]\n",
    "#features_x = [\"x231\"]\n",
    "#features = [X_labels.index(i) for i in features_x]\n",
    "### Feature by range (0-indexed):\n",
    "# features = itertools.chain(range(75,85),range(90,95))\n",
    "\n",
    "#set r2 cutoff\n",
    "r2_cutoff = 0.4\n",
    "r2_values = []\n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind], y)\n",
    "    fit_line = intercept+slope*X[:,f_ind]\n",
    "    r2 = r_value**2\n",
    "    r2_values.append(r2)\n",
    "    if r2 >= r2_cutoff:\n",
    "        print(feature, X_names[f_ind])\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.hist(X[:,f_ind], bins=\"auto\")\n",
    "        plt.ylabel(\"frequency\",fontsize=12)\n",
    "        plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.set_style(\"white\")\n",
    "        sns.regplot(X[:,f_ind],y,ci=95,truncate=False)\n",
    "        x_max=np.max(X[:,f_ind])\n",
    "        x_min=np.min(X[:,f_ind])\n",
    "        y_max=np.max(y)\n",
    "        y_min=np.min(y)\n",
    "        delta_x = 0.05 * (x_max-x_min)\n",
    "        delta_y = 0.05 * (y_max-y_min)\n",
    "        plt.xlim([x_min-delta_x,x_max+delta_x])\n",
    "        plt.ylim([y_min-delta_y,y_max+delta_y])\n",
    "        #plt.scatter(X[:,f_ind], y,color=\"black\",marker=\".\",alpha=0.5,s=150)\n",
    "        #plt.plot(X[:,f_ind],fit_line,color=\"black\")\n",
    "        plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=18)\n",
    "        plt.ylabel(\"y\",fontsize=18)  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        #toggle these two lines to either show or show and save the plots\n",
    "        plt.show()\n",
    "        #plt.savefig(\"plotname.png\",dpi=300)\n",
    "        \n",
    "        if p_value > 0.01:\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2f}\".format(r_value**2,p_value))\n",
    "        else:\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "        print(\"\\n--------------------------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot a feature vs. another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:04:06.733261Z",
     "start_time": "2021-11-08T21:04:06.114915Z"
    }
   },
   "outputs": [],
   "source": [
    "# one comparison plot at a time\n",
    "\n",
    "# select two features to visualize\n",
    "# can be integer-index of features, or string with x-number\n",
    "f_ind_1 = \"x171\"\n",
    "f_ind_2 = \"x71\"\n",
    "\n",
    "if type(f_ind_1) == str:\n",
    "    [f_ind_1,f_ind_2] = [X_labels.index(i) for i in [f_ind_1,f_ind_2]]\n",
    "\n",
    "print(X_labels[f_ind_1], X_names[f_ind_1])\n",
    "print(X_labels[f_ind_2], X_names[f_ind_2])\n",
    "print(\"\\n{} samples\".format(np.shape(X[:,f_ind_1])[0]))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind_1],X[:,f_ind_2])\n",
    "fit_line = intercept+slope*X[:,f_ind_1]\n",
    "print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "\n",
    "plt.figure(figsize=(13, 4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(X[:,f_ind_1], bins=\"auto\",color=\"black\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(X_labels[f_ind_1] + \" \" + X_names[f_ind_1])\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(X[:,f_ind_2], bins=\"auto\",color=\"black\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(X_labels[f_ind_2] + \" \" + X_names[f_ind_2])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X[:,f_ind_1], X[:,f_ind_2],color=\"black\",marker=\"s\")    \n",
    "#plt.plot(X[:,f_ind_1],fit_line)\n",
    "plt.xlabel(X_labels[f_ind_1] + \" \" + X_names[f_ind_1])\n",
    "plt.ylabel(X_labels[f_ind_2] + \" \" + X_names[f_ind_2])\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:11:52.526082Z",
     "start_time": "2021-11-08T21:11:40.925395Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multpile plots set by ranges\n",
    "# shows only plots as set by criteria below\n",
    "\n",
    "feats_to_check1 = itertools.chain(range(48,49),range(72,73)) \n",
    "feats_to_check2 = range(150,190) \n",
    "\n",
    "for i in feats_to_check1:\n",
    "    num1 = i\n",
    "    x_format1 = \"x{}\".format(num1 + 1)\n",
    "    if type(x_format1) == str:\n",
    "            [x_format1] = [X_labels.index(i) for i in [x_format1]]\n",
    "    for p in feats_to_check2:\n",
    "        num2 = p\n",
    "        x_format2 = \"x{}\".format(num2)\n",
    "        \n",
    "        #---\n",
    "        if type(x_format2) == str:\n",
    "            [x_format2] = [X_labels.index(i) for i in [x_format2]]\n",
    "        #print(i,x_format1,type(x_format1))\n",
    "        #print(p,x_format2,type(x_format2))\n",
    "\n",
    "        if x_format1 != x_format2:\n",
    "            print(X_labels[x_format1], X_names[x_format1])\n",
    "            print(X_labels[x_format2], X_names[x_format2])\n",
    "            print(\"\\n{} samples\".format(np.shape(X[:,x_format1])[0]))\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,x_format1],X[:,x_format2])\n",
    "            fit_line = intercept+slope*X[:,x_format1]\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "            \n",
    "            #show only plots satisfying these criteria:\n",
    "            if r_value > 0.2:\n",
    "                plt.figure(figsize=(13, 4))\n",
    "                \n",
    "                plt.subplot(1,3,1)\n",
    "                plt.hist(X[:,x_format1], bins=\"auto\",color=\"black\")\n",
    "                plt.ylabel(\"frequency\")\n",
    "                plt.xlabel(X_labels[x_format1] + \" \" + X_names[x_format1])\n",
    "                plt.subplot(1,3,2)\n",
    "                plt.hist(X[:,x_format2], bins=\"auto\",color=\"black\")\n",
    "                plt.ylabel(\"frequency\")\n",
    "                plt.xlabel(X_labels[x_format2] + \" \" + X_names[x_format2])\n",
    "                \n",
    "                plt.subplot(1,3,3)\n",
    "                plt.scatter(X[:,x_format1], X[:,x_format2],color=\"black\",marker=\"s\")    \n",
    "                #plt.plot(X[:,f_ind_1],fit_line)\n",
    "                \n",
    "                # label by x number\n",
    "                #plt.xlabel(X_labels[num1])\n",
    "                #plt.ylabel(X_labels[num2])\n",
    "                # label by x name           \n",
    "                plt.xlabel(X_labels[x_format1] + \" \" + X_names[x_format1])\n",
    "                plt.ylabel(X_labels[x_format2] + \" \" +X_names[x_format2])\n",
    "                plt.tight_layout()\n",
    "            \n",
    "            \n",
    "                plt.show()   \n",
    "                \n",
    "            print(\"\\n---------------------------------------------------------------------------------------------------------------\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bubble Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parm v parm, sized by y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:23:43.345949Z",
     "start_time": "2021-11-22T22:23:43.182536Z"
    }
   },
   "outputs": [],
   "source": [
    "# set x, y, and size dimensions, set plot title\n",
    "bp_x = \"x49\"\n",
    "bp_y = \"x73\"\n",
    "bp_size = \"s2_3.5h_%yield(avg)\"\n",
    "bp_title = \"parm v parm sized by y\"\n",
    "\n",
    "\n",
    "#figure size\n",
    "plt.figure(figsize=(8,8))\n",
    "# use the scatterplot function to build the bubble map\n",
    "sns.scatterplot(data=inp, \n",
    "                x=bp_x,                   #set x\n",
    "                y=bp_y,                   #set y\n",
    "                size=bp_size,             #set size\n",
    "                sizes=(50, 300),          #set size range\n",
    "                alpha=0.7,                #set transparency\n",
    "                color=\"mediumslateblue\",  #set color of points\n",
    "                marker=\"D\")               #set marker shape\n",
    "\n",
    "#toggle this to label data points with IDs\n",
    "#for i in range(0,inp.shape[0]):\n",
    "#    plt.text(inp[bp_x][i]-0.002, inp[bp_y][i]+0.0001, inp.index[i], size=\"small\")\n",
    "    \n",
    "#set x,y limits, place legend outside of plot, set title\n",
    "plt.xlim((round(min(inp[bp_x]),2)-0.01),(round(max(inp[bp_x]),2)+0.01)) \n",
    "plt.ylim((round(min(inp[bp_y]),2)-0.01),(round(max(inp[bp_y]),2)+0.01))\n",
    "plt.legend(bbox_to_anchor=(1.01,1),loc=2,borderaxespad=0)\n",
    "plt.title(bp_title)\n",
    "\n",
    "# show or save the graph\n",
    "plt.show()\n",
    "#plt.savefig(\"plotname\",format=png,dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with virtual entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:53:30.219589Z",
     "start_time": "2021-11-22T21:53:30.032697Z"
    }
   },
   "outputs": [],
   "source": [
    "#plots exp entires by size and virtual entries on top with different marker\n",
    "#requires a column labeled \"virtual\" with 1=virtual structure, 0=experimental structure. put 0s in the ycolumns for these\n",
    "\n",
    "# set x, y, and size dimensions, set plot title\n",
    "bp_x = \"x49\"\n",
    "bp_y = \"x73\"\n",
    "bp_size = \"s2_3.5h_%yield(avg)\"\n",
    "bp_title = \"parm v parm sized by y\"\n",
    "#set colors for exp (0) and virtual (1)\n",
    "palette = {0:\"tomato\",\n",
    "           1:\"royalblue\"}\n",
    "\n",
    "#figure size\n",
    "plt.figure(figsize=(8,8))\n",
    "# use the scatterplot function to build the bubble map\n",
    "sns.scatterplot(data=bp_df, \n",
    "                x=bp_x,                   #set x\n",
    "                y=bp_y,                   #set y\n",
    "                size=bp_size,             #set size\n",
    "                sizes=(50, 500),          #set size range\n",
    "                alpha=0.7,                #set transparency\n",
    "                hue=inp['virtual'],       #color points by virtual or exp\n",
    "                style=inp['virtual'],     #set point markers by virtual or exp\n",
    "                palette=palette)          #use defined colors\n",
    "\n",
    "#toggle this to label data points or not\n",
    "#for i in range(0,inp.shape[0]):\n",
    "#    plt.text(inp[bp_x][i]+0.0002, inp[bp_y][i], inp.index[i], size=\"small\")\n",
    "\n",
    "#set x,y limits, place legend outside of plot, set title\n",
    "plt.xlim((round(min(inp[bp_x]),2)-0.005),(round(max(inp[bp_x]),2)+0.005)) \n",
    "plt.ylim((round(min(inp[bp_y]),2)-0.005),(round(max(inp[bp_y]),2)+0.005))\n",
    "plt.legend(bbox_to_anchor=(1.01,1),loc=2,borderaxespad=0)\n",
    "plt.title(bp_title)\n",
    "\n",
    "# show or save the graph\n",
    "plt.show()\n",
    "#plt.savefig(\"plotname\",format=png,dpi=300)\n",
    "\n",
    "print(\"note: virtual ligands sized arbitrarily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:04:28.743501Z",
     "start_time": "2021-11-03T22:04:26.819738Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment this line to use an interactive plot \n",
    "# %matplotlib notebook\n",
    "\n",
    "corrmap = np.corrcoef(X.T)\n",
    "\n",
    "plt.matshow(corrmap)\n",
    "plt.xticks(range(len(X_labels)),X_labels, fontsize=10, rotation=90)\n",
    "plt.yticks(range(len(X_labels)),X_labels, fontsize=10)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:04:33.402043Z",
     "start_time": "2021-11-03T22:04:28.980867Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uncomment this line to use an interactive plot \n",
    "#%matplotlib notebook\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "corrmap = np.corrcoef(X.T)\n",
    "\n",
    "plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(corrmap,center=0, annot=False, cmap=\"coolwarm\", cbar=True) #linewidths=0.5\n",
    "plt.xticks(range(len(X_labels)),X_labels, fontsize=10, rotation=90)\n",
    "plt.yticks(range(len(X_labels)),X_labels, fontsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-node Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:05:24.703822Z",
     "start_time": "2021-11-03T22:05:24.542255Z"
    }
   },
   "outputs": [],
   "source": [
    "# import graphviz \n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1).fit(X, y)\n",
    "print(\"Accuracy: {:.2f}\".format(dt.score(X, y)))\n",
    "\n",
    "feat = int(np.where(dt.feature_importances_ != 0)[0])\n",
    "print(X_labels[feat],X_names[feat])\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(X[:,feat], y)    \n",
    "plt.xlabel(X_names[feat])\n",
    "plt.ylabel(\"y\")  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "# dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "#                      feature_names=X_names,   \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify highest and lowest group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:05:27.330641Z",
     "start_time": "2021-11-03T22:05:26.828983Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find features that separate the group with highest/lowest output y\n",
    "# change the definition of bins in the histogram to get control over how these groups are defined\n",
    "y_hist,y_bin_edges = np.histogram(y,bins=\"auto\")\n",
    "y_class_low = [or i in y]0 if i < y_bin_edges[1] else 1 for i in y]\n",
    "y_class_high = [1 if i > y_bin_edges[-2] else 0 f\n",
    "\n",
    "plt.figure(figsize=(8.5, 4))\n",
    "n_classes = 2\n",
    "plot_colors = \"rg\"\n",
    "plot_step = 0.02\n",
    "y_classes = [np.asarray(y_class_low),np.asarray(y_class_high)]\n",
    "for y_class,i in zip(y_classes,[1,2]):\n",
    "    dt = DecisionTreeClassifier(max_depth=1).fit(X, y_class)\n",
    "    feat = int(np.where(dt.feature_importances_ != 0)[0])    \n",
    "    a = (\"f1_score: {:.2f}\".format(metrics.f1_score(y_class,dt.predict(X))))\n",
    "#    b = (\"auc: {:.2f}\".format(metrics.roc_auc_score(y_class,dt.predict(X))))\n",
    "    print(X_labels[feat],X_names[feat])    \n",
    "    xpltlabel = X_labels[feat] + \"\\n\" + X_names[feat] + \"\\n\" + a# + \"\\n\" + b\n",
    "\n",
    "    dt_plt = DecisionTreeClassifier(max_depth=1).fit(X[:,feat].reshape(-1, 1), y_class)\n",
    "    x_min, x_max = X[:, feat].min(), X[:, feat].max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    dx,dy = x_max-x_min,y_max-y_min\n",
    "    xx, yy = np.meshgrid(np.arange(x_min-0.04*dx, x_max+0.04*dx, plot_step),\n",
    "                         np.arange(y_min-0.04*dy, y_max+0.04*dy, plot_step))\n",
    "    \n",
    "    plt.subplot(1,2,i)\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = dt_plt.predict(xx.ravel().reshape(-1, 1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=\"Pastel1\")#plt.cm.RdYlBu)\n",
    "\n",
    "    plt.xlabel(xpltlabel)\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_class == i)\n",
    "        plt.scatter(X[idx, feat], y[idx], c=color,cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# dot_data = tree.export_graphviz(dt_plt, out_file=None, \n",
    "#                      feature_names=[x_names[feat]],   \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T03:12:00.181835Z",
     "start_time": "2019-07-07T03:12:00.176867Z"
    }
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:05:37.140233Z",
     "start_time": "2021-11-03T22:05:36.941768Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide samples into two classes based on y_cut, find the feature that most clearly distinguishes these groups\n",
    "y_cut = 50\n",
    "\n",
    "#this can be done on a subset of features\n",
    "# features = [i for i in itertools.chain(range(75,85),range(90,95))]\n",
    "# features = [i for i in range(38,135)]\n",
    "features = range(np.shape(X)[1])\n",
    "X_use = X[:,features]\n",
    "\n",
    "y_class = np.array([0 if i < y_cut else 1 for i in y])\n",
    "n_classes=2\n",
    "dt = DecisionTreeClassifier(max_depth=1).fit(X_use, y_class)\n",
    "\n",
    "feat = features[int(np.where(dt.feature_importances_ != 0)[0])]\n",
    "print(X_labels[feat],X_names[feat])\n",
    "\n",
    "dt_plt = DecisionTreeClassifier(max_depth=1).fit(X[:,feat].reshape(-1, 1), y_class)\n",
    "print(\"Decision threshold = {:.2f}\\nAccuracy: {:.2f}\\nf1_score: {:.2f}\\nN = {}\".format(\n",
    "        dt_plt.tree_.threshold[0],\n",
    "        dt_plt.score(X[:,feat].reshape(-1, 1), y_class),\n",
    "        metrics.f1_score(y_class,dt_plt.predict(X[:,feat].reshape(-1, 1))),\n",
    "        len(y)\n",
    "    ))\n",
    "\n",
    "plot_colors = \"rg\"\n",
    "plot_step = 0.02\n",
    "x_min, x_max = X[:,feat].min(), X[:,feat].max()\n",
    "y_min, y_max = y.min(), y.max()\n",
    "dx,dy = x_max-x_min,y_max-y_min\n",
    "xx, yy = np.meshgrid(np.arange(x_min-0.04*dx, x_max+0.04*dx, plot_step),\n",
    "                     np.arange(y_min-0.04*dy, y_max+0.04*dy, plot_step))\n",
    "\n",
    "plt.figure(figsize=(4, 4))    \n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "Z = dt_plt.predict(xx.ravel().reshape(-1, 1))\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=\"Pastel1\")#plt.cm.RdYlBu)\n",
    "xpltlabel = X_labels[feat] + \"\\n\" + X_names[feat]\n",
    "\n",
    "plt.xlabel(xpltlabel)\n",
    "plt.ylabel(\"y\")  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y_class == i)\n",
    "    plt.scatter(X[idx, feat], y[idx], c=color,cmap=plt.cm.RdYlBu, edgecolor='black', s=15)    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:07:48.116503Z",
     "start_time": "2021-11-03T22:07:46.199886Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for public threshold script, see https://github.com/SigmanGroup/Threshold\n",
    "\n",
    "# divide samples into two classes based on y_cut, visualize how features separate these classes\n",
    "y_cut = 50\n",
    "class_weight = {0:1,1:20}\n",
    "\n",
    "#select features here\n",
    "features = range(len(X_labels))   # iterate over all features\n",
    "#features = itertools.chain(range(7,20))\n",
    "\n",
    "y_class = np.array([0 if i < y_cut else 1 for i in y])\n",
    "n_classes = 2\n",
    "plot_colors = \"rg\"\n",
    "plot_step = 0.02 #0.002\n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    print(feature, X_names[f_ind])\n",
    "    dt = DecisionTreeClassifier(max_depth=1,class_weight=class_weight).fit(X[:,f_ind].reshape(-1, 1), y_class)\n",
    "    print(\"Decision threshold = {:.2f}\\nAccuracy: {:.2f}\\nf1_score: {:.2f}\\nN = {}\".format(\n",
    "        dt.tree_.threshold[0],\n",
    "        dt.score(X[:,f_ind].reshape(-1, 1), y_class),\n",
    "        metrics.f1_score(y_class,dt.predict(X[:,f_ind].reshape(-1, 1))),\n",
    "        len(y)\n",
    "    ))\n",
    "    \n",
    "    dt_plt = DecisionTreeClassifier(max_depth=1).fit(X[:,f_ind].reshape(-1, 1), y_class)\n",
    "    x_min, x_max = X[:,f_ind].min(), X[:,f_ind].max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    dx,dy = x_max-x_min,y_max-y_min\n",
    "    xx, yy = np.meshgrid(np.arange(x_min-0.04*dx, x_max+0.04*dx, plot_step),\n",
    "                         np.arange(y_min-0.04*dy, y_max+0.04*dy, plot_step))\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))    \n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = dt_plt.predict(xx.ravel().reshape(-1, 1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=\"Pastel1\")#plt.cm.RdYlBu)\n",
    "    xpltlabel = X_labels[f_ind] + \"\\n\" + X_names[f_ind]\n",
    "\n",
    "    plt.xlabel(xpltlabel)\n",
    "    plt.ylabel(\"y\")  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_class == i)\n",
    "        plt.scatter(X[idx, f_ind], y[idx], c=color,cmap=plt.cm.RdYlBu, edgecolor='black', s=15)    \n",
    "    \n",
    "    #plt.savefig(name,dpi=300,bbox_inches = 'tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(\"\\n----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation: Training/Test set split, Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:58:43.936962Z",
     "start_time": "2020-11-23T10:58:43.924995Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform transformations on y\n",
    "y_orig = y.copy() # this is a backup of y\n",
    "\n",
    "#toggle these options to manipulate y\n",
    "\n",
    "#exp\n",
    "# y = np.exp(y_orig)\n",
    "\n",
    "#log-transformation: either remove all samples with y=0 () or add a small amount to y to avoid log(0).\n",
    "#y = np.log(y+0.0001)\n",
    "#or\n",
    "#y = np.log(y[y.nonzero()[0]])\n",
    "# y_labels_orig,X_orig = y_labels.copy(),X.copy()\n",
    "# y_labels = y_labels[y.nonzero()[0]]\n",
    "# X = X[y.nonzero()[0]]\n",
    "\n",
    "#absolute value\n",
    "# y = abs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T22:17:11.312050Z",
     "start_time": "2021-09-23T22:17:11.305037Z"
    }
   },
   "outputs": [],
   "source": [
    "# preselection option 1\n",
    "# comment-out first line in Train/test split if using this\n",
    "\n",
    "# remove samples based on a feature-value \n",
    "select_feature = \"x8\" \n",
    "\n",
    "# define cutoff \n",
    "mask_prop = X[:,X_labels.index(select_feature)]<5.62   \n",
    "\n",
    "X_sel,y_sel,y_labels_sel = X[mask_prop],y[mask_prop],y_labels[mask_prop]\n",
    "print(\"Shape X: {}\".format(X_sel.shape))\n",
    "print(\"Shape y: {}\".format(y_sel.shape)) \n",
    "print(\"Shape labels: {}\".format(y_labels_sel.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T17:14:00.823514Z",
     "start_time": "2020-01-10T17:14:00.819555Z"
    }
   },
   "outputs": [],
   "source": [
    "# preselection\n",
    "# comment-out first line in Train/test split if using this\n",
    "\n",
    "# remove samples based on index (0-indexed)\n",
    "\n",
    "exclude = [38] #+[i for i in range(26,37)]\n",
    "print(exclude)\n",
    "mask = [i for i in range(len(y)) if i not in exclude]\n",
    "X_sel,y_sel,y_labels_sel = X[mask],y[mask],y_labels[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T20:09:20.635784Z",
     "start_time": "2021-11-23T20:09:20.462241Z"
    }
   },
   "outputs": [],
   "source": [
    "# comment this line out if preselection was performed\n",
    "X_sel,y_sel,labels_sel,exclude = X,y,y_labels,[]\n",
    "\n",
    "# select method of split:\n",
    "# random\n",
    "# y_equidist - picks points that evenly span the output variable y. \n",
    "#              Normally doesn't pick highest/lowest values but this can be activated by changing the variable no_extrapolation in the respective section\n",
    "# ks - Kennard Stone algorithm picks points based on an even distriution in feature space\n",
    "# define - give a list of sample indices for either VS or TS in the corresponding code section \n",
    "# none - all samples in TS\n",
    "\n",
    "# the numbers in the variables VS and TS refer to the original 0-indexed sample numbers \n",
    "\n",
    "split = \"y_equidist\"\n",
    "test_ratio = 0.3 \n",
    "\n",
    "if split == \"random\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sel, y_sel, random_state=randomstate+3, test_size=test_ratio)    \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "    \n",
    "elif split == \"define\":\n",
    "   # numbers according to sample lines in the excel sheet (that is, including indexes of 'excluded' samples)\n",
    "    # for defining the TS, change the names of TS and VS in the next three lines\n",
    "    #TS = [16,27,25,5,13,9,29,7]\n",
    "    TS = []\n",
    "    VS = [16,27,25,5,13,9,29,7]\n",
    "    #TS = [i-1 for i in VS] # this can be commented out if 0-indexed numbers were defined above\n",
    "    #VS = [i for i in range(X.shape[0]) if i not in VS and i not in exclude]\n",
    "    TS = [i for i in range(X.syhape[0]) if i not in VS and i not in exclude]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS]\n",
    "    \n",
    "elif split == \"ks\":\n",
    "    import kennardstonealgorithm as ks\n",
    "    TS,VS = ks.kennardstonealgorithm(X_sel,int((1-test_ratio)*np.shape(X_sel)[0]))\n",
    "    X_train, y_train,X_test, y_test = X_sel[TS], y_sel[TS],X_sel[VS], y_sel[VS]\n",
    "  \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]   \n",
    "\n",
    "elif split == \"y_equidist\":\n",
    "    no_extrapolation = True\n",
    "    \n",
    "    import kennardstonealgorithm as ks\n",
    "    if no_extrapolation:\n",
    "        minmax = [np.argmin(y_sel),np.argmax(y_sel)]\n",
    "        y_ks = np.array(([i for i in y_sel if i not in [np.min(y_sel),np.max(y_sel)]]))\n",
    "        y_ks_indices = [i for i in range(len(y_sel)) if i not in minmax]\n",
    "        \n",
    "        # indices relative to y_ks:\n",
    "        VS_ks,TS_ks = ks.kennardstonealgorithm(y_ks.reshape(np.shape(y_ks)[0],1),int((test_ratio)*(2+np.shape(y_ks)[0])))\n",
    "        # indices relative to y_sel:\n",
    "        TS_ = sorted([y_ks_indices[i] for i in list(TS_ks)]+minmax)\n",
    "        VS_ = sorted([y_ks_indices[i] for i in VS_ks])\n",
    "\n",
    "    else:\n",
    "        VS_,TS_ = ks.kennardstonealgorithm(y_sel.reshape(np.shape(y)[0],1),int((test_ratio)*np.shape(y)[0]))\n",
    "        X_train, y_train, X_test, y_test = X[TS_], y[TS_], X[VS_], y[VS_]\n",
    "        # indices relative to y\n",
    "        self.TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "        self.VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "elif split == \"none\":\n",
    "    TS, VS = [i for i in range(X.shape[0]) if i not in exclude],[]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS]\n",
    "    \n",
    "else: \n",
    "    raise ValueError(\"split option not recognized\")\n",
    "     \n",
    "\n",
    "print(\"TS: {}\".format(TS))\n",
    "print(\"VS: {}\".format(VS))\n",
    "print(\"y_mean TS: {:.3f}\".format(np.mean(y_train)))\n",
    "print(\"y_mean VS: {:.3f}\".format(np.mean(y_test)))\n",
    "print(\"Shape X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape X_test:  {}\".format(X_test.shape))   \n",
    "plt.figure(figsize=(5, 5))\n",
    "hist,bins = np.histogram(y_sel,bins=\"auto\")#\"auto\"\n",
    "plt.hist(y_train, bins, alpha=0.5, label='y_train',color=\"black\")\n",
    "plt.hist(y_test, bins, alpha=0.5, label='y_test')\n",
    "# plt.legend(loc='best')\n",
    "plt.xlabel(\"y\",fontsize=20)\n",
    "plt.ylabel(\"N samples\",fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T20:09:21.883665Z",
     "start_time": "2021-11-23T20:09:21.869702Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale features by mean/variance, pick the relevant option (normally: StandardScaler)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "X_all_sc = scaler.transform(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-terms/Interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T19:25:31.104797Z",
     "start_time": "2020-01-07T19:25:30.224203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add polynomial features/interaction terms\n",
    "# this is not yet implemented properly in some sections. \n",
    "# for 5.1-manual selection: specify cross-term with space between the components: x1 x40 + x6\n",
    "# Essentially only section 5.2 can use cross-terms so far\n",
    "# don't run this twice\n",
    "\n",
    "polyfeats = PolynomialFeatures(degree=2,interaction_only=False,include_bias=False)\n",
    "X_train_p = polyfeats.fit_transform(X_train_sc)  #[:,[1,8,0]])\n",
    "X_test_p = polyfeats.transform(X_test_sc)\n",
    "X_all_p = polyfeats.transform(X_all_sc)\n",
    "\n",
    "def add_to_x(matchobj):\n",
    "    if \"^\" in matchobj.group(0):\n",
    "        n = int(matchobj.group(0).split(\"^\")[0])+1\n",
    "        return(\"{} x{}\".format(n,n))\n",
    "    else:\n",
    "        return(str(int(matchobj.group(0))+1))\n",
    "    \n",
    "pfnames = np.asarray([re.sub(\"[0-9]+(\\^[0-9])*\",add_to_x,st) for st in polyfeats.get_feature_names()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T19:25:36.477761Z",
     "start_time": "2020-01-07T19:25:33.137640Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter out non-significant crossterms based on p-value with target variable\n",
    "p_val_cutoff = 0.005\n",
    "\n",
    "r2s = []\n",
    "pvals = []\n",
    "for f_ind,feature in enumerate(X_train_p.T):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(feature, y_train)    \n",
    "    r2s.append(r_value**2)\n",
    "    pvals.append(p_value)\n",
    "    \n",
    "r2s_ = np.asarray(r2s)\n",
    "pvals_ = np.asarray(pvals)\n",
    "\n",
    "keep_p_ = [i[0] for i in np.argwhere(pvals_<p_val_cutoff) if i not in range(np.shape(X_all)[1])]\n",
    "keep_p = [i for i in range(np.shape(X_all)[1])] + keep_p_\n",
    "\n",
    "def sub_label_to_name(matchobj):\n",
    "    return(X_labelname_dict[matchobj.group(0)])\n",
    "def sub_labelname(matchobj):\n",
    "    return(matchobj.group(0)+\" \"+X_labelname_dict[matchobj.group(0)])\n",
    "    \n",
    "pfnames = np.asarray([re.sub(\"[0-9]+(\\^[0-9])*\",add_to_x,st) for st in polyfeats.get_feature_names()])\n",
    "X_p_labels = list(np.reshape(pfnames[keep_p],len(keep_p)))\n",
    "X_p_names = [re.sub(\"x[0-9]+\",sub_label_to_name,st) for st in X_p_labels]\n",
    "X_p_labelname = [re.sub(\"x[0-9]+\",sub_labelname,st) for st in X_p_labels]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train_p[:,keep_p])\n",
    "X_test_sc = scaler.transform(X_test_p[:,keep_p])\n",
    "X_all_sc = scaler.transform(X_all_p[:,keep_p])\n",
    "\n",
    "X_labels = X_p_labels\n",
    "X_names = X_p_names\n",
    "X_labelname = X_p_labelname\n",
    "\n",
    "print(\"{} cross-terms with p-value < {}\".format(len(keep_p_),p_val_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear modelling, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual selection of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T22:08:17.244442Z",
     "start_time": "2021-11-17T22:08:16.773061Z"
    }
   },
   "outputs": [],
   "source": [
    "#provide an x__ model (string, any order of terms)\n",
    "features_x =  \"x49 +x73\"#\n",
    "features_py = sorted([X_labels.index(i.strip()) for i in features_x.split(\"+\")])\n",
    "\n",
    "# features_py = []\n",
    "#features = sorted([int(i[1:]) for i in re.findall(\"x\\d+\",features_x)])\n",
    "#features_py = [i-1 for i in features]\n",
    "\n",
    "\n",
    "X_train_sel = X_train_sc[:,features_py]\n",
    "X_test_sel = X_test_sc[:,features_py]\n",
    "lr = Ridge(alpha=1E-5).fit(X_train_sel, y_train)\n",
    "\n",
    "#lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "alphas = np.logspace(-6,3,10)\n",
    "\n",
    "#for i in alphas:\n",
    "#lr = Ridge(alpha=i).fit(X_train_sel, y_train)     \n",
    "#print(f'\\nalpha: {i}')\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores = repeated_k_fold(X_train_sel,y_train,k=5,n=200)\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(features_py)[i]]) for i in range(len(features_py))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores.mean(), kfoldscores.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "\n",
    "# settings for plot and saving\n",
    "#plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=\"plotname\",label=\"$ΔΔG^{≠}$\",loo_pred=loo_train)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"Yield\",loo_pred=loo_train)\n",
    "    \n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:45:06.041580Z",
     "start_time": "2021-11-03T22:45:04.231435Z"
    }
   },
   "outputs": [],
   "source": [
    "# add all individual features to the manual model\n",
    "add_df = pd.DataFrame(index=X_labelname,columns=[\"label_sep\",\"label_abs\",\"Training R2\",\"Training Q2\"],dtype=float)\n",
    "\n",
    "update_model = False\n",
    "for f_ind in range(len(X_labels)):\n",
    "    features_iter = features_py + [f_ind]    \n",
    "    X_train_sel = X_train_sc[:,features_iter]\n",
    "    X_test_sel = X_test_sc[:,features_iter]\n",
    "    # lr = Ridge(alpha=1E-1).fit(X_train_sel, y_train)\n",
    "    lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train,lr)\n",
    "    add_df.iloc[f_ind,:] = [X_labels[f_ind],\"x\"+str(f_ind+1),lr.score(X_train_sel, y_train),q2]\n",
    "\n",
    "if update_model and X_labelname.index(add_df['Training Q2'].idxmax()) not in features_py:\n",
    "    features_py.append(X_labelname.index(add_df['Training Q2'].idxmax()))\n",
    "add_df.sort_values(by=['Training Q2'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:45:06.449973Z",
     "start_time": "2021-11-03T22:45:06.405093Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove each individual feature from the manual model\n",
    "print(\"\\n\"+\" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "\n",
    "rem_df = pd.DataFrame(index=[X_labelname[i] for i in features_py],\n",
    "                      columns=[\"Training R2\",\"Training Q2\"])\n",
    "for f_ind in features_py:\n",
    "    features_iter = [i for i in features_py if i != f_ind]\n",
    "#     print(feature, x_names[f_ind])\n",
    "    X_train_sel = X_train_sc[:,features_iter]\n",
    "    X_test_sel = X_test_sc[:,features_iter]\n",
    "    # lr = Ridge(alpha=1E-1).fit(X_train_sel, y_train)\n",
    "    lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train,lr)\n",
    "    rem_df.loc[X_labelname[f_ind],:] = [lr.score(X_train_sel, y_train),q2]\n",
    "\n",
    "rem_df.sort_values(by=['Training Q2'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward stepwise selection based on p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:26:41.963967Z",
     "start_time": "2021-11-04T20:26:40.754531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward stepwise selection based on p-value\n",
    "# threshold values refer to p-value of individual features\n",
    "threshold_in = 0.05\n",
    "threshold_out = 0.075 # must be larger than threshold_in\n",
    "\n",
    "use_manual_feats = False # if True, model from previous section will be used as starting point\n",
    "\n",
    "import stepwise_selection2 as step_s\n",
    "if not use_manual_feats:\n",
    "    features_py=[]\n",
    "\n",
    "features_py = step_s.stepwise_selection(pd.DataFrame(X_train_sc), y_train,\n",
    "                    initial_list=features_py,threshold_in=threshold_in,threshold_out=threshold_out,verbose=True)\n",
    "\n",
    "print(\"\\n\"+\" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\n\"+\" + \".join([X_labelname[i] for i in sorted(features_py)]))\n",
    "\n",
    "X_train_sel = X_train_sc[:,features_py]\n",
    "X_test_sel = X_test_sc[:,features_py]\n",
    "lr = RidgeCV(alphas=np.logspace(-6,3,10), cv=3).fit(X_train_sel, y_train) \n",
    "print(f'\\nalpha: {lr.alpha_}')\n",
    "#lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100,reg=LinearRegression())\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(features_py)[i]]) for i in range(len(features_py))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu)) \n",
    "    \n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"\",loo_pred=loo_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other forward feature selection implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:19:05.633799Z",
     "start_time": "2021-11-08T21:19:05.428321Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scikit-learn - forward feature selection\n",
    "# largely useless\n",
    "# options for criteria: \n",
    "# mutual_info_regression, f_regression\n",
    "# select number of features with k\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "criteria = f_regression\n",
    "skb = SelectKBest(criteria,k=4).fit(X_train_sc,y_train)\n",
    "selected_feats = skb.get_support(indices=True)\n",
    "print(\" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\n\"+\" + \".join([X_names[i] for i in sorted(selected_feats)]))\n",
    "\n",
    "X_train_sel = skb.transform(X_train_sc)\n",
    "X_test_sel = skb.transform(X_test_sc)\n",
    "lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n",
    "# uncomment to add model to candidate list\n",
    "# keepmodels.append(features_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:27:56.618817Z",
     "start_time": "2021-11-04T20:27:36.467461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward stepwise selection based on AIC (\"aic\") or Q2 (\"q2\")\n",
    "criteria = \"aic\"\n",
    "#criteria = \"q2\"\n",
    "\n",
    "import forwardselect_q5 as fsq\n",
    "\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "a,b = fsq.Forward_Select(df,\"y\",\"Regression\",criteria)\n",
    "selected_feats = [int(i[1:]) for i in b]\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\n\"+\" + \".join([X_names[i] for i in sorted(selected_feats)]))\n",
    "\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "print(\"\\n\\n\")\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n",
    "# uncomment to add model to candidate list\n",
    "# keepmodels.append(features_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward stepwise selection keeping a set of candidates at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:29:43.957679Z",
     "start_time": "2021-11-04T20:29:23.692078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward stepwise selection keeping a set of candidates at each step\n",
    "n_steps = 3\n",
    "n_candidates = 20\n",
    "collin_criteria = 0.5 # this is R2\n",
    "skipfeatures = [] #[\"x4\",\"x3\"]\n",
    "\n",
    "import ForwardStepCandidates_2 as fsc\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "df.drop(skipfeatures,axis=1,inplace=True)\n",
    "\n",
    "results,models,scores,sortedmodels,candidates = fsc.ForwardStep_py(df,'y',\n",
    "                    n_steps=n_steps,n_candidates=n_candidates,collin_criteria=collin_criteria)\n",
    "model_sel = results.loc[0,\"Model\"]\n",
    "selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\"\\nBest model:\")\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[candidates[0]].terms])+\"\\n\")\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View models as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:51:09.948164Z",
     "start_time": "2021-11-03T22:51:09.915280Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view best models\n",
    "results.sort_values(by=['Q^2'],ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:51:14.905446Z",
     "start_time": "2021-11-03T22:51:14.869514Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view models with a specific number of terms\n",
    "selmods = results[results.n_terms <=2].sort_values(by=['Q^2'],ascending=False)\n",
    "selmods.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:52:07.079113Z",
     "start_time": "2021-11-03T22:52:07.049200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example for filtering results\n",
    "#filter to find models containing specified parameters\n",
    "\n",
    "l1 = [*range(138, 163, 1)] \n",
    "l2 = []\n",
    "for i in l1:\n",
    "    a = \"x{}\".format(i)\n",
    "    l2.append(a)\n",
    "\n",
    "selmods2 = results.loc[[i for i in results.index if any(x in l2 for x in results.loc[i,'Model']) and \"x200\" not in results.loc[i,\"Model\"]]].sort_values(by=['Q^2'],ascending=False)\n",
    "\n",
    "selmods2.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:52:54.652810Z",
     "start_time": "2021-11-03T22:52:54.628842Z"
    }
   },
   "outputs": [],
   "source": [
    "# example for filtering results\n",
    "\n",
    "selmods2 = results.loc[[i for i in results.index if \"x113\" in results.loc[i,\"Model\"] and \"x49\" not in results.loc[i,\"Model\"]]][results.n_terms < 5].sort_values(by=['Q^2'],ascending=False)\n",
    "selmods2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T06:41:09.900600Z",
     "start_time": "2019-07-15T06:41:09.840203Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter models that contain more than one term that is also in a reference model\n",
    "reference_model = 0 # this number refer to the index in 'results' or 'selmods', whichever is used \n",
    "use_df = results # or: selmods\n",
    "\n",
    "uniquemods = {use_df.loc[reference_model,\"Model\"]:reference_model}\n",
    "for ind in use_df.index:\n",
    "    selmod = use_df.loc[ind,\"Model\"]\n",
    "    if len(selmod) <= 2:\n",
    "        continue\n",
    "        \n",
    "    add = True\n",
    "    for mod in uniquemods.keys():\n",
    "        if len([i for i in mod if i in selmod]) >= 2:\n",
    "            add = False\n",
    "            break\n",
    "    if add:      \n",
    "        uniquemods[use_df.loc[ind,\"Model\"]] = ind\n",
    "    \n",
    "    \n",
    "print(len(uniquemods.keys()))\n",
    "selmods2 = results.loc[uniquemods.values()]\n",
    "selmods2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:30:19.662074Z",
     "start_time": "2021-11-04T20:30:19.275110Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize other models\n",
    "model_sel = results.loc[12,\"Model\"]\n",
    "\n",
    "#other ways of selecting models:\n",
    "# model_sel = results.iloc[selmods.index[3],0]\n",
    "# model_sel = results.iloc[785,0]\n",
    "# model_sel = (\"x100\",\"x31\")\n",
    "\n",
    "\n",
    "selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "\n",
    "print(\"Split method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[model_sel].terms])+\"\\n\")\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:21:57.116397Z",
     "start_time": "2021-11-08T21:20:17.187724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print all models that are within a specified criteria (if statement below)\n",
    "# results.index will look at all models, selmods.index will look at filtered models\n",
    "\n",
    "#for i in results.index:\n",
    "for i in selmods.index:\n",
    "    model_sel = results.loc[i,\"Model\"]\n",
    "    \n",
    "    #other ways of selecting models:\n",
    "    # model_sel = results.iloc[selmods.index[3],0]\n",
    "    # model_sel = results.iloc[785,0]\n",
    "    # model_sel = (\"x100\",\"x31\")\n",
    "    \n",
    "    \n",
    "    selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "    X_train_sel = X_train_sc[:,selected_feats]\n",
    "    X_test_sel = X_test_sc[:,selected_feats]\n",
    "    print(models[model_sel].formula)\n",
    "    print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[model_sel].terms])+\"\\n\")\n",
    "    lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "    y_pred_train = lr.predict(X_train_sel)\n",
    "    y_pred_test =  lr.predict(X_test_sel)\n",
    "    \n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "    kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "    \n",
    "    testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "    trainr2 = lr.score(X_train_sel, y_train)\n",
    "    \n",
    "    #set criteria here \n",
    "    if testr2 >= 0.65 and q2>=0.6:\n",
    "        print(\"\\nSplit method: {}\".format(split))\n",
    "        print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "        \n",
    "        print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "        print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "        \n",
    "        print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "        print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "        \n",
    "        print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "        print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "    \n",
    "        if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "            print(\"\\n\"+random.choice(insu))\n",
    "        \n",
    "        plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "    \n",
    "        #model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "        #print(model.summary())\n",
    "        \n",
    "    print(\"____________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression, no feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:32:24.304743Z",
     "start_time": "2021-11-04T20:32:23.943498Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "linm = Ridge().fit(X_train_sc, y_train)\n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "parm_range = np.logspace(-4,4,9)\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    linm = Ridge(alpha=parm).fit(X_train_sc, y_train)\n",
    "    q2,loo_train = loo.q2(X_train_sc,y_train,Ridge(alpha=parm))\n",
    "    \n",
    "    y_pred_train = linm.predict(X_train_sc)\n",
    "    y_pred_test =  linm.predict(X_test_sc)\n",
    "    #print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,metrics.r2_score(y_pred_test,y_test)))\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(linm.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "    #print(lr.score(X_train_sel,y_train),lr.score(X_test_sel,y_test))\n",
    "        \n",
    "    r2s.append(linm.score(X_train_sc, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "\n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "linm = Ridge(alpha=bestparm).fit(X_train_sc, y_train)\n",
    "y_pred_train = linm.predict(X_train_sc)\n",
    "y_pred_test =  linm.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:32:43.649061Z",
     "start_time": "2021-11-04T20:32:42.905974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lasso feature selection\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "parm_range = np.logspace(-4,1,6)\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    lasso = Lasso(alpha=parm).fit(X_train_sc, y_train)\n",
    "    X_train_sel = X_train_sc[:,np.where(lasso.coef_!=0)[0]]\n",
    "    X_test_sel = X_test_sc[:,np.where(lasso.coef_!=0)[0]]\n",
    "    try:\n",
    "        q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "        lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "        y_pred_train = lr.predict(X_train_sel)\n",
    "        y_pred_test =  lr.predict(X_test_sel)\n",
    "        #print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,metrics.r2_score(y_pred_test,y_test)))\n",
    "        print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "        #print(lr.score(X_train_sel,y_train),lr.score(X_test_sel,y_test))\n",
    "    except:\n",
    "        pass\n",
    "    print(\"     Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))\n",
    "    # print(np.where(lr.coef_ != 0)[1])\n",
    "    \n",
    "    r2s.append(lasso.score(X_train, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "\n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "lasso = Lasso(alpha=bestparm).fit(X_train_sc, y_train)\n",
    "y_pred_train = lasso.predict(X_train_sc)\n",
    "y_pred_test =  lasso.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)    \n",
    "    \n",
    "# llbic = LassoLarsIC(criterion=\"bic\").fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(llbic.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(llbic.coef_!=0)[0]]\n",
    "# print(\"\\n\\nLassoLarsIC bic\")\n",
    "# try:\n",
    "#     q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "#     print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(llbic.score(X_train_sc, y_train),q2,llbic.score(X_test_sc, y_test)))\n",
    "# except:\n",
    "#     pass\n",
    "# print(\"Number of features used: {}\".format(np.sum(llbic.coef_ != 0)))\n",
    "\n",
    "# llaic = LassoLarsIC(criterion=\"aic\").fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(llaic.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(llaic.coef_!=0)[0]]\n",
    "# print(\"\\n\\nLassoLarsIC aic\")\n",
    "# try:\n",
    "#     q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "#     print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(llaic.score(X_train_sc, y_train),q2,llaic.score(X_test_sc, y_test)))\n",
    "# except:\n",
    "#     pass\n",
    "# print(\"Number of features used: {}\".format(np.sum(llaic.coef_ != 0)))\n",
    "\n",
    "# lassocv = LassoCV(cv=LeaveOneOut()).fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(lassocv.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(lassocv.coef_!=0)[0]]\n",
    "# q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "# print(\"\\n\\nLassoCV\")\n",
    "# print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lassocv.score(X_train_sc, y_train),q2,lassocv.score(X_test_sc, y_test)))\n",
    "# print(\"Number of features used: {}\".format(np.sum(lassocv.coef_ != 0)))\n",
    "# print(np.where(lassocv.coef_ != 0)[1])\n",
    "\n",
    "llcv = LassoLarsCV(cv=LeaveOneOut()).fit(X_train_sc, y_train)\n",
    "X_train_sel = X_train_sc[:,np.where(llcv.coef_!=0)[0]]\n",
    "X_test_sel = X_test_sc[:,np.where(llcv.coef_!=0)[0]]\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "print(\"\\n\\nLassoLarsCV\")\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(llcv.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "print(\"Number of features used: {}\".format(np.sum(llcv.coef_ != 0)))\n",
    "# print(np.where(llcv.coef_ != 0)[1])\n",
    "y_pred_train = llcv.predict(X_train_sc)\n",
    "y_pred_test =  llcv.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:01.630278Z",
     "start_time": "2021-11-04T20:33:00.977701Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "encv = ElasticNetCV(l1_ratio=[.01,.05,.66,.1,.2,.3, .5, .7, .9, .95, .99, 1],\n",
    "#                     n_alphas=500,\n",
    "                    alphas=np.logspace(-1,4,100),\n",
    "                    cv=3,n_jobs=-1,max_iter=1000000).fit(X_train_sc, y_train)\n",
    "X_train_sel = X_train_sc[:,np.where(encv.coef_!=0)[0]]\n",
    "X_test_sel = X_test_sc[:,np.where(encv.coef_!=0)[0]]\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train,Ridge(alpha=encv.alpha_))\n",
    "y_pred_train = encv.predict(X_train_sc)\n",
    "y_pred_test =  encv.predict(X_test_sc)\n",
    "print(\"\\n\\nElasticNetCV\")\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(encv.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "print(\"Number of features used: {}\".format(np.sum(encv.coef_ != 0)))\n",
    "print(\"Best hyperparameters: l1_ratio = {}, alpha = {}\".format(encv.l1_ratio_,encv.alpha_))\n",
    "\n",
    "\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:12.560161Z",
     "start_time": "2021-11-04T20:33:12.448401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Orthogonal Matching Pursuit\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "parm_range = range(1,10)\n",
    "print(np.shape(X_train_sc))\n",
    "print(np.shape(y_train))\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=parm).fit(X_train_sc, y_train)\n",
    "    X_train_sel = X_train_sc[:,np.where(omp.coef_!=0)[0]]\n",
    "    X_test_sel = X_test_sc[:,np.where(omp.coef_!=0)[0]]\n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "    y_pred_train = omp.predict(X_train_sc)\n",
    "    y_pred_test =  omp.predict(X_test_sc)\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(omp.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "    print(\"     \"+\" + \".join([\"x\"+str(i+1) for i in np.where(omp.coef_ != 0)[0]]))\n",
    "    #print(\"     Number of features used: {}\".format(np.sum(lr.coef_ != 0)))\n",
    "    \n",
    "\n",
    "# ompcv = OrthogonalMatchingPursuitCV(cv=LeaveOneOut(),n_jobs=-1).fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(ompcv.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(ompcv.coef_!=0)[0]]\n",
    "# q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "# print(\"\\n\\nOrthogonalMatchingPursuitCV\")\n",
    "# print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(ompcv.score(X_train_sc, y_train),q2,ompcv.score(X_test_sc, y_test)))\n",
    "# print(\"Number of features used: {}\".format(np.sum(ompcv.coef_ != 0)))\n",
    "\n",
    "# print(\"\\n\"+\" + \".join([\"x\"+str(i+1) for i in np.where(ompcv.coef_!=0)[0]]))\n",
    "# print(\"\\n\"+\" + \".join([X_names[i] for i in np.where(ompcv.coef_!=0)[0]]))\n",
    "\n",
    "# y_pred_train = ompcv.predict(X_train_sc)\n",
    "# y_pred_test =  ompcv.predict(X_test_sc)\n",
    "# plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:17.815213Z",
     "start_time": "2021-11-04T20:33:17.481107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kernel Ridge Regression \n",
    "# kernel options: linear, poly, rbf\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio)) \n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "print(\"\\n\\nKernelRidge\")\n",
    "\n",
    "kernel=\"poly\" #rbf (only works if properties are related)\n",
    "degree=2  #2 simulates crossterms \n",
    "\n",
    "parm_range = np.logspace(-3,3,7)\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    kr = KernelRidge(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        alpha=parm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "    y_pred_train = kr.predict(X_train_sc)\n",
    "    y_pred_test =  kr.predict(X_test_sc)\n",
    "    q2,loo_train = loo.q2(X_train_sc,y_train,KernelRidge(kernel=kernel,degree=degree,alpha=parm))\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(\n",
    "        kr.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "    r2s.append(kr.score(X_train, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "    \n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "kr = KernelRidge(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        alpha=bestparm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "y_pred_train = kr.predict(X_train_sc)\n",
    "y_pred_test =  kr.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:23.350395Z",
     "start_time": "2021-11-04T20:33:22.952944Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVR\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "print(\"\\n\\nSupport Vector Regression\")\n",
    "\n",
    "kernel=\"poly\"\n",
    "degree=2\n",
    "gamma=\"auto\"\n",
    "\n",
    "parm_range = np.logspace(-3,3,15)\n",
    "for parm in parm_range:\n",
    "    print(\"{:.2E}\".format(parm))\n",
    "    svr = SVR(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        gamma=gamma,\n",
    "        C=parm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "    y_pred_train = svr.predict(X_train_sc)\n",
    "    y_pred_test =  svr.predict(X_test_sc)\n",
    "    q2,loo_train = loo.q2(X_train_sc,y_train,SVR(kernel=kernel,degree=degree,gamma=gamma,C=parm))\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(\n",
    "        svr.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "    r2s.append(svr.score(X_train, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "    \n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "svr = SVR(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        gamma=gamma,\n",
    "        C=bestparm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "y_pred_train = svr.predict(X_train_sc)\n",
    "y_pred_test =  svr.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "   \n",
    "\n",
    "# keepmodels_[svr] = ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:34:05.479348Z",
     "start_time": "2021-11-04T20:34:03.666109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regression with Principal Components\n",
    "\n",
    "for npca in range(1,9):\n",
    "    pca = PCA(n_components=npca)\n",
    "    pca.fit(scaler.transform(X_sel))\n",
    "#     pca.fit(X_train_sc)\n",
    "    X_train_pca = pca.transform(X_train_sc)\n",
    "    X_test_pca = pca.transform(X_test_sc)\n",
    "\n",
    "    pca_score = pca.explained_variance_ratio_\n",
    "    pca_values = pca.singular_values_\n",
    "    V = pca.components_\n",
    "\n",
    "    linr = LinearRegression().fit(X_train_pca, y_train)\n",
    "#     linr = Ridge(alpha=1).fit(X_train_pca,y_train)\n",
    "    y_pred_train = linr.predict(X_train_pca)\n",
    "    y_pred_test =  linr.predict(X_test_pca)\n",
    "    q2,loo_train = loo.q2(X_train_pca,y_train,LinearRegression())\n",
    "    print(\"\\nSplit method: {}\".format(split))\n",
    "    print(\"Test ratio: {}\".format(test_ratio))\n",
    "    print(\"\\nPC Regression {}\".format(npca))\n",
    "    print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(\n",
    "        linr.score(X_train_pca, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "\n",
    "\n",
    "    plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n",
    "    \n",
    "# # virtual screening\n",
    "# X_screen_sel = pca.transform(X_all_sc)\n",
    "# y_pred_vscreen = linr.predict(X_screen_sel)\n",
    "# y_vscreen[\"PCA5\"] = y_pred_vscreen\n",
    "\n",
    "\n",
    "# keepmodels_[PCA(n_components=2).fit(scaler.transform(X_sel))] = (\"n_components=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:34:18.872212Z",
     "start_time": "2021-11-04T20:34:18.001568Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random forest regression\n",
    "\n",
    "rf  = RandomForestRegressor(n_estimators=500,random_state=42,n_jobs=None,max_features=None,max_depth=None).fit(\n",
    "    X_train_sc, y_train)\n",
    "# rf = GradientBoostingRegressor(\n",
    "#     n_estimators=50,\n",
    "#     subsample=.6,\n",
    "#     max_depth=2,\n",
    "#     random_state=42,\n",
    "#     max_features=None,\n",
    "#     alpha=0.9,\n",
    "#     ).fit(X_train_sc, y_train)\n",
    "y_pred_train = rf.predict(X_train_sc)\n",
    "y_pred_test =  rf.predict(X_test_sc)\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "print(\"Training R2;Test R2;{:.2f};{:.2f}\".format(\n",
    "    rf.score(X_train_sc, y_train),r2_val(y_test,y_pred_test,y_train)))\n",
    "# print(np.where(llcv.coef_ != 0)[1])\n",
    "\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)   \n",
    "\n",
    "# keepmodels_[rf] = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "314px",
    "width": "313px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325.016px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "400"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 959.666666,
   "position": {
    "height": "981.263px",
    "left": "1534.33px",
    "right": "20px",
    "top": "5px",
    "width": "631.037px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
